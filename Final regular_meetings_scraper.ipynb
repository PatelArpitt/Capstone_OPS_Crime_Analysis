{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pre-requisite libraries for the project\n",
    "\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "import os\n",
    "import PyPDF2, io\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setting up environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Selenium Framework (Chromium Headless Browser)\n",
    "\n",
    "def initialize_chromium():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--headless\") # If the user wants to use Chromium with a GUI, comment this line.\n",
    "    global driver; driver = webdriver.Chrome(options = options)\n",
    "\n",
    "\n",
    "# Release Selenium Framework (Chromium Headless Browser)\n",
    "\n",
    "def release_chromium():\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the Regular Meetings data to a DataFrame\n",
    "\n",
    "def meetings_extraction():\n",
    "  global current_year; current_year = 2023\n",
    "  meeting_no = 1\n",
    "  reg_meets_all = []\n",
    "  reg_meets = []\n",
    "  reg_meets_cancelled = []\n",
    "  reg_meets_without_verbals = []\n",
    "\n",
    "  while current_year > 2010:\n",
    "    url = f'https://ottawapoliceboard.ca/opsb-cspo/{current_year}-meetings.html'\n",
    "\n",
    "    driver.get(url)\n",
    "    page_src = driver.page_source\n",
    "    soup = BeautifulSoup(page_src, 'html.parser')\n",
    "    meetings_list = soup.find('table').find('tbody').find_all('tr')\n",
    "\n",
    "\n",
    "    # Fetch only regular meetings information from the list of all meetings\n",
    "    for index, tr in enumerate(reversed(meetings_list)):\n",
    "        td = tr.find_all('td')\n",
    "        if td[3].get_text().strip() == 'Regular Meeting':\n",
    "          if current_year < 2013: date = f'{td[0].get_text().strip()}, {current_year}'\n",
    "          else: date = td[0].get_text().strip()\n",
    "\n",
    "          reg_meets_all.append({\n",
    "              'Meeting #': meeting_no,\n",
    "              'Date': date,\n",
    "              'Location': td[1].get_text().strip(),\n",
    "              'Time': td[2].get_text().strip(),\n",
    "              'Meeting Type': td[3].get_text().strip(),\n",
    "              'Meeting Page': td[0].find('a').get('href'),\n",
    "              'Chief Verbal Report Present': '',\n",
    "              'Verbal Report File URL': ''\n",
    "            })\n",
    "          meeting_no = meeting_no + 1\n",
    "    print(f'Regular Meetings of Year {current_year} processed.')\n",
    "    current_year = current_year - 1\n",
    "  reg_meets_all_df = pd.DataFrame(reg_meets_all)\n",
    "\n",
    "\n",
    "# Remove Cancelled Regular Meetings\n",
    "  for x in reg_meets_all:\n",
    "    if x['Location'] == 'CANCELLED':\n",
    "      reg_meets_cancelled.append(x)\n",
    "    else:\n",
    "      reg_meets.append(x)\n",
    "  reg_meets_cancelled_df = pd.DataFrame(reg_meets_cancelled)\n",
    "\n",
    "  for meet in reg_meets:\n",
    "    url = meet['Meeting Page']\n",
    "    domain = '{uri.scheme}://{uri.netloc}/'.format(uri = urlparse(url))\n",
    "    driver.get(url)\n",
    "    page_src = driver.page_source\n",
    "    soup = BeautifulSoup(page_src, 'html.parser')\n",
    "\n",
    "\n",
    "    # Finds all the reports based on different variations of \"Chief's Verbal Report\" taken into consideration\n",
    "    elems = soup.find_all(text = lambda t: t and any(x in t for x in [\"Chief’s verbal report\", \"Chief's verbal report\", \"CHIEF’S VERBAL REPORT\", \"CHIEF'S VERBAL REPORT\"]))\n",
    "    for el in elems:\n",
    "      if ((el.find_parent()).find_parent()).find_parent().find_all('a', href = lambda href: href and \"filestream\" in href):\n",
    "        urls = ((el.find_parent()).find_parent()).find_parent().find_all('a', href = lambda href: href and \"filestream\" in href)\n",
    "        if url:\n",
    "          for a in urls:\n",
    "              verbal_report_url = f\"{domain}{a['href']}\"\n",
    "              meet.update({'Chief Verbal Report Present': 'Yes'})\n",
    "              meet.update({'Verbal Report File URL': verbal_report_url})\n",
    "        else:\n",
    "          meet.update({'Chief Verbal Report Present': 'No'})\n",
    "          meet.update({'Verbal Report File URL': '-'})\n",
    "      elif (((el.find_parent()).find_parent()).find_parent()).find_parent().find_all('a', href = lambda href: href and \"filestream\" in href):\n",
    "        urls = (((el.find_parent()).find_parent()).find_parent()).find_parent().find_all('a', href = lambda href: href and \"filestream\" in href)\n",
    "        if urls:\n",
    "          for a in urls:\n",
    "            if \"filestream\" in a['href']:\n",
    "              verbal_report_url = f\"{domain}{a['href']}\"\n",
    "              meet.update({'Chief Verbal Report Present': 'Yes'})\n",
    "              meet.update({'Verbal Report File URL': verbal_report_url})\n",
    "            else:\n",
    "              meet.update({'Chief Verbal Report Present': 'No'})\n",
    "              meet.update({'Verbal Report File URL': '-'})\n",
    "        else:\n",
    "          meet.update({'Chief Verbal Report Present': 'No'})\n",
    "          meet.update({'Verbal Report File URL': '-'})\n",
    "\n",
    "\n",
    "  reg_meets_df = pd.DataFrame(reg_meets)\n",
    "  export_to_excel(reg_meets_df)\n",
    "\n",
    "\n",
    "# Export the DataFrame to an Excel Sheet\n",
    "\n",
    "def export_to_excel(df):\n",
    "  df.to_excel('Final regular_meetings_output.xlsx', sheet_name = 'Regular Meetings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send an E-Mail to the recipient address entered in the input box along with the regular_meetings excel file attachment\n",
    "\n",
    "def send_mail():\n",
    "    recipient_mail = input(\"Enter an E-mail address to receive missing chief's verbal list\")\n",
    "    to_mail = recipient_mail\n",
    "    gmail_usr = os.getenv('GMAIL_USR')\n",
    "    gmail_pwd = os.getenv('GMAIL_PWD')\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"Missing Chief's Verbals List\"\n",
    "    msg['From'] = gmail_usr\n",
    "    msg['To'] = to_mail\n",
    "\n",
    "    msgText = MIMEText(\"\\n This mail consists of regular meetings list where Chief's Verbal document is missing \\n p.f.a. \\n\", 'html')\n",
    "    msg.attach(msgText)\n",
    "\n",
    "    filename = \"Final regular_meetings_output.xlsx\"\n",
    "    xlsx = MIMEApplication(open(filename, 'rb').read())\n",
    "    xlsx.add_header('Content-Disposition', 'attachment', filename = 'Final regular_meetings_output.xlsx')\n",
    "    msg.attach(xlsx)\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP(\"smtp.gmail.com\", 587) as smtpserver:\n",
    "            smtpserver.ehlo()\n",
    "            smtpserver.starttls()\n",
    "            smtpserver.login(gmail_usr, gmail_pwd)\n",
    "            smtpserver.sendmail(f'{gmail_usr}<Team-8 SMTP Mail Client>', to_mail, msg.as_string())\n",
    "            smtpserver.quit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print ('email sent!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to go through each Chief Verbal Document URL and extract each sentence to an Excel File\n",
    "\n",
    "def extract_text_from_documents():\n",
    "    global crimes_data_df\n",
    "    crimes_data_df = pd.DataFrame()\n",
    "    \n",
    "    # Read the Excel file\n",
    "    excel_file = 'Final regular_meetings_output.xlsx'\n",
    "    reports_df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Assigning the column containing PDF links named as 'pdf_urls'\n",
    "    reports_df = reports_df.dropna()\n",
    "    pdf_urls = reports_df[['Date', 'Verbal Report File URL']]\n",
    "\n",
    "    # Read each PDF\n",
    "    for index, row in pdf_urls.iterrows():\n",
    "        resp = requests.get(row['Verbal Report File URL'])\n",
    "        with io.BytesIO(resp.content) as file:\n",
    "            # Create a PDF object\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Initialize a variable to store the extracted text\n",
    "            global corpus\n",
    "            corpus = []\n",
    "            page_text = \"\"\n",
    "            \n",
    "            # Extract the text from each page of the PDF. We have only one page.\n",
    "            for page in pdf.pages:\n",
    "                page_text += page.extract_text()\n",
    "            \n",
    "            page_text = page_text.split('.')\n",
    "            for sentence in page_text:\n",
    "                sentence = sentence.lower()\n",
    "                sentence = re.sub(\"&lt;/?.*&gt;\", \"&lt;&gt; \", sentence)\n",
    "                sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "                sentence = sentence.strip()\n",
    "                if len(sentence.split(' ')) >= 4:\n",
    "                    corpus.append(sentence)\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        print(\"link started: \", index, row['Verbal Report File URL'])\n",
    "        convert_to_df(corpus, row['Date'])\n",
    "        crimes_data_df = crimes_data_df.append(crime_df)\n",
    "        print(\"link over: \", index, row['Verbal Report File URL'])\n",
    "        print(crimes_data_df)\n",
    "\n",
    "    export_excel()\n",
    "    print(\"Crime Analysis Completed! Please check the output file: 'Final all_extracted_sentences.xlsx' for the output.\")\n",
    " \n",
    "# Function to convert all of the corpus sentences to a singular dataframe\n",
    "def convert_to_df(corpus, date):\n",
    "    global crime_df\n",
    "    crime_df = pd.DataFrame({'sentences': corpus})\n",
    "    crime_df.insert(0, 'Date', date)\n",
    "    \n",
    "# Export the modified DataFrame\n",
    "def export_excel():\n",
    "    print(crimes_data_df)\n",
    "    output_path = 'Final all_extracted_sentences.xlsx'\n",
    "    crimes_data_df.to_excel(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution cell with all essential function run in one-go\n",
    "\n",
    "initialize_chromium()\n",
    "meetings_extraction()\n",
    "release_chromium()\n",
    "send_mail()\n",
    "extract_text_from_documents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
